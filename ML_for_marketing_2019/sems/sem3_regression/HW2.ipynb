{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://justaklikaway.files.wordpress.com/2014/05/shut-up-and-take-my-money.jpg\" height=\"400\" width=\"400\"> \n",
    "\n",
    "# <center> ML для маркетинга. <br>  <br> Сюжетная арка 1: продажи </center>\n",
    "\n",
    "В этом семестре мы с вами пройдём через несколько сюжетных арок. Первой такой аркой будут продажи. Им будет посвящена первая серия из домашек и семинаров. \n",
    "\n",
    "\n",
    "### Задача:\n",
    "\n",
    "Мы будем работать с датасетом __bikes_rent.csv__, в котором по дням записаны календарная информация и погодные условия, характеризующие автоматизированные пункты проката велосипедов, а также число прокатов в этот день. Последнее мы будем предсказывать; таким образом, мы будем решать задачу регрессии.\n",
    "\n",
    "\n",
    "#  Эпизод II (атака моделей) \n",
    "\n",
    "В прошлом задании мы предобработали данные. Пришло время оценивать по ним модели. ВПЕРЁД! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# пакеты для картиночек \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')  # правильный (наиболее красивый) стиль у графиков\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для того, чтобы на одной картинке смотреть те графики с прогнозами.\n",
    "def plot_yreal_ypred(y_test, y_train, y_test_hat, y_train_hat):\n",
    "    \"\"\"\n",
    "        Рисует картинку для прогнозов регрессии \n",
    "    \"\"\"\n",
    "    \n",
    "    margin = 0.1 # отступ на границах\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(y_train, y_train_hat, color=\"red\", alpha=0.5)\n",
    "    plt.xlabel('Истинные значения')\n",
    "    plt.ylabel('Предсказанные значения')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    train_min = min(y_train)\n",
    "    train_max = max(y_train)\n",
    "    plt.xlim(train_min - margin, train_max + margin)\n",
    "    plt.ylim(train_min - margin, train_max + margin)\n",
    "    plt.plot([-10000, 10000], [-10000, 10000])\n",
    "    plt.title('Train set', fontsize=20)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(y_test, y_test_hat, color=\"red\", alpha=0.5)\n",
    "    plt.xlabel('Истинные значения')\n",
    "    plt.ylabel('Предсказанные значения')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    test_min = min(y_test)\n",
    "    test_max = max(y_test)\n",
    "    plt.xlim(test_min - margin, test_max + margin)\n",
    "    plt.ylim(test_min - margin, test_max + margin)\n",
    "    plt.plot([-10000, 10000], [-10000, 10000])\n",
    "    plt.title('Test set', fontsize=20)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузите данные для обучения модели, которые вы сохранили у себя на компьютере при решении первой домашки.  Удалите из выборки главные компоненты. Они нам не нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../sem1_data_prepare/data_train.csv', sep='\\t')\n",
    "\n",
    "y = df['cnt'] # то, что прогнозируем \n",
    "\n",
    "# Удаляем лишние колонки \n",
    "df = df.drop(['cnt', 'pca_1', 'pca_2', 'pca_3'], axis=1)\n",
    "\n",
    "# названия фичей для прогозирования\n",
    "features = list(df.columns)  \n",
    "\n",
    "# фичи\n",
    "X = df.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__  Разбейте выборку на тренировочную и тестовую. В прошлый раз мы делали дополнительную выборку. Её подгружать не надо. Она для следующей домашки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Возьмите RMSE в качестве метрики качества. Для этого нужно написать свою функцию. Постройте наивный прогноз (среднее) и найдите для него RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Запустите код с разбиением выборки на тренировочную и тестовую, подсчётом наивного прогноза и RMSE по нему несколько раз. НЕ НАДО НИЧЕГО КОПИРОВАТЬ. ПРОСТО ПЕРЕЗАПУСТИТЕ КОД ТРИ РАЗА. Меняется ли RMSE? Почему оно меняется? К чему плохому это может привести при обучении? Как это обычно исправляют? \n",
    "\n",
    "__Ответ:__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Оцените линейную регрессию. Насколько удалось улучшить качество прогнозирования в сравнении с наивным прогнозом?  Визуализируйте прогнозы функцией `plot_yreal_ypred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Какими получились значения перед коэффициентами у вашей модели?  Как думаете, почему такое произошло?  Чтобы вспомнить, вернитесь в первую домашку и посмотрите на корреляционную матрицу. \n",
    "\n",
    "__Ответ:__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Обучите Lasso-регрессию. В качестве силы регуляризации возьмите $\\alpha = 40$. \n",
    "\n",
    "* Каким получилось качество прогноза? \n",
    "* Что в модели произошло с коэффициентами?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ответ:__  \n",
    "\n",
    "* Качество улучшилось по сравнению с наивным прогнозом. \n",
    "* Некоторые коэффициенты занулились, а все остальные больше не такие огромные \n",
    "* Занулились коэффициенты перед признаками, которые друг-друга дублируют. \n",
    "* Например, у нас было в данных две температуры. Осталась только одна. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[0]__  Изучите код в этом пункте и прочитайте выводы. Подумайте об этом. \n",
    "\n",
    "В случае линейных моделей, обычно, используют два вида регуляризации: Ridge и Lasso. Первая прибавляет к MSE квадраты коэффицентов, а вторая модули. Давайте посмотрим какая между ними разница."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge  # подгружаем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим много-много моделей с разными силами регуляризации $\\alpha$ и посмотрим что получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(1, 100, 2)   # задали диапазон для силы регуляризатора\n",
    "\n",
    "# матрицы для весов перед коэффициентами (число регрессоров)*(число признаков)\n",
    "coefs_lasso = np.zeros((alphas.shape[0], X.shape[1]))\n",
    "coefs_ridge = np.zeros((alphas.shape[0], X.shape[1]))\n",
    "\n",
    "i = 0\n",
    "for alph in alphas:\n",
    "    rg = Ridge(alpha=alph)  # для каждого alph обучаем модель\n",
    "    ls = Lasso(alpha=alph)\n",
    "    rg.fit(X,y)\n",
    "    ls.fit(X,y)\n",
    "    coefs_ridge[i] = rg.coef_  # и запоминаем коэффициенты\n",
    "    coefs_lasso[i] = ls.coef_\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от L2-регуляризации (Ridge), L1 (Lasso) обнуляет веса при некоторых признаках. Давайте пронаблюдаем, как меняются веса при увеличении коэффициента регуляризации $\\alpha$ (в лекции коэффициент при регуляризаторе мог быть обозначен другой буквой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for coef, feature in zip(coefs_lasso.T, features):\n",
    "    plt.plot(alphas, coef, label=feature, color=np.random.rand(3))\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 0.95))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"feature weight\")\n",
    "plt.title(\"Lasso\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for coef, feature in zip(coefs_ridge.T, features):\n",
    "    plt.plot(alphas, coef, label=feature, color=np.random.rand(3))\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.4, 0.95))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"feature weight\")\n",
    "plt.title(\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинки вышли красивыми. Обратите внимание, что регуляризатор Lasso агрессивнее уменьшает веса. Подумайте с чем это связано. Если делать `alpha` очень большим, веса зануляются. В случае Ridge такого не происходит. Веса становятся всё ближе к нулю, но зануления не происходит.  Из-за того, что Lasso зануляет некоторые признаки, его можно использовать для отбора самых важных признаков. Дальше будем работать именно с ним. \n",
    "\n",
    "Итак, мы видим, что при изменении `alpha` модель по-разному подбирает коэффициенты признаков. Нам нужно выбрать наилучшее `alpha`. Для этого, во-первых, нам нужна метрика качества. Будем использовать в качестве метрики сам оптимизируемый функционал метода наименьших квадратов, то есть MSE (Mean Square Error).\n",
    "\n",
    "Во-вторых, нужно понять, на каких данных эту метрику считать. Нельзя выбирать `alpha` по значению MSE на обучающей выборке, потому что тогда мы не сможем оценить, как модель будет делать предсказания на новых для нее данных. Если мы выберем одно разбиение выборки на обучающую и тестовую, то настроимся на конкретные \"новые\" данные, и вновь можем переобучиться. \n",
    "\n",
    "Именно такую настройку вы наблюдали выше, когда запускали код с наивным прогнозом много раз подряд. Поэтому будем делать несколько разбиений выборки, на каждом пробовать разные значения `alpha`, а затем усреднять MSE. Удобнее всего делать такие разбиения кросс-валидацией, то есть разделить выборку на $K$ частей, или блоков, и каждый раз брать одну из них как тестовую, а из оставшихся блоков составлять обучающую выборку. \n",
    "\n",
    "Подбирать параметр `alpha` в `sklearn` совсем просто: для этого есть `GridSearchCV`. Мы уже сталкивались с примером применения этой функции на семинаре. Попробуйте с помощью неё перебрать список из альф и подыскать оптимальное. Параметр cv отвечает за то, на сколько частей делится выборка. Поставьте `cv=5`. Также укажите параметр `scoring = neg_mean_squared_error`. Это задаст функцию потерь, на которую будет ориентироваться `GridSearchCV` при переборе. Назовите переменную, в которой будет находиться перебор __grid_cv_lasso.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Подберите для Lasso-регрессии с помощью поиска по решётке оптимальное значение $\\alpha$.  Каким оказалось это значение? \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Каким получается качество прогноза для модели с оптимальным значением $\\alpha$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[1]__ Наконец, как принято в анализе данных, давайте проинтерпретируем результат. Проинтерпретируйте последнюю обученую модель. У каких признаков наибольшие положительные коэфициенты? У каких наибольшие отрицательные? Логично ли утверждать, что чем больще/меньше эти признаки, тем выше/ниже спрос на велосипеды? Какие коэффициенты занулились? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишите сюда символы свои"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ответ:__  \n",
    "\n",
    "__[1]__ В прошлой домашке, когда мы придумывали фичи, мы предположили, что спрос на велосипеды зависит от скорости ветра квадратично, по параболе. Подтвердилось ли это предположение? \n",
    "\n",
    "__Ответ:__    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[0]__ Сохраните лучшую модель на компьютере. Она понадобится нам для решения последней части этой домашки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(<переменная с моделью>, 'model_hw.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключение\n",
    "\n",
    "Итак, мы посмотрели, как можно следить за адекватностью линейной модели, как отбирать признаки и как грамотно, по возможности, не настраиваясь на какую-то конкретную порцию данных, подбирать коэффициент регуляризации. \n",
    "\n",
    "Стоит отметить, что с помощью кросс-валидации удобно подбирать лишь небольшое число параметров (1, 2, максимум 3), потому что для каждой допустимой их комбинации нам приходится несколько раз обучать модель, а это времязатратный процесс, особенно если нужно обучаться на больших объемах данных.\n",
    "\n",
    "# Обратная связь \n",
    "\n",
    "Выстрадал код? Расскажи о страданиях [в анонимке](https://docs.google.com/forms/d/e/1FAIpQLSeDLENjGbfgdEvR6UgMuo5D8u6F91-ExCoqd7dDHxWnheRwZQ/viewform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
